# Mini data pipeline: CSV â†’ ETL (Python/pandas) â†’ PostgreSQL â†’ FastAPI API

![CI](https://github.com/paripariume/mini-etl-fastapi-postgres/actions/workflows/ci.yml/badge.svg)

## Design Intent (Production-minded)
- **Process separation**: API ã¨ ETL ã¯ç‹¬ç«‹ãƒ—ãƒ­ã‚»ã‚¹ã€‚çŠ¶æ…‹ã¯ DB ã«é›†ç´„
- **Metrics persistence**: ETL æˆåŠŸ/å¤±æ•—ã‚’ DB ã«ä¿æŒã— /metrics ã§ç›£è¦–
- **Idempotency**: PostgreSQL ON CONFLICT ã§å†å®Ÿè¡Œå®‰å…¨æ€§
- **Testability**: pytest ã«ã‚ˆã‚‹æœ€å°ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ
- **Operability**: å†å®Ÿè¡Œãƒ»ç›£è¦–ãƒ»éšœå®³æ¤œå‡ºã‚’å‰æã«è¨­è¨ˆ

## Architecture
API (FastAPI) ----> Postgres <---- ETL Script (pandas + SQLAlchemy)
                          |
                          â””â”€â”€ ETL Metrics Table (health signal)


## ðŸš€ What
This repository provides a mini data pipeline demonstration:
- CSV input data â†’ data transformation using Python/pandas  
- Loading into PostgreSQL database  
- Serving analytics via FastAPI  
- Containerised using Docker and docker-compose  
- Includes pytest tests and CI integration for reproducibility

## ðŸ“¦ Tech Stack
- Python 3.12  
- FastAPI  
- SQLAlchemy 2.x  
- pandas  
- PostgreSQL 16  
- Docker & Docker Compose  
- pytest  
- GitHub Actions (CI)

## ðŸ§© Endpoints
| Endpoint                  | Description                  |
|---------------------------|------------------------------|
| `/health`                 | Service health check         |
| `/orders/summary`         | Summary of orders by customer|
| `/orders/daily?start=&end=` | Daily aggregates by date     |
| `/metrics`                | Internal load metrics (last run, count) |

## ðŸ› ï¸ Usage
```bash
git clone https://github.com/paripariume/mini-etl-fastapi-postgres.git
cd mini-etl-fastapi-postgres
docker compose up -d --build
docker compose exec api python -m src.etl.load
curl http://localhost:8000/orders/summary
